{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version :  1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from pathlib import Path\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "print(\"PyTorch version : \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (6420, 2) 6420\n",
      "Validation Set: (2140, 2) 2140\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Train.csv\")\n",
    "df_val = pd.read_csv(\"Val.csv\")\n",
    "\n",
    "df_train.drop(['id'], axis = 1, inplace = True)\n",
    "df_val.drop(['id'], axis = 1, inplace = True)\n",
    "\n",
    "print(\"Training Set:\"% df_train.columns, df_train.shape, len(df_train))\n",
    "print(\"Validation Set:\"% df_val.columns, df_val.shape, len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1  States reported 1121 deaths a small rise from ...  real\n",
       "2  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no empty tweet or unlabel data\n"
     ]
    }
   ],
   "source": [
    "if df_train['tweet'].isnull().sum() == 0 and df_train['label'].isnull().sum() == 0:\n",
    "    print('There is no empty tweet or unlabel data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tweet\n",
      "label       \n",
      "fake    3060\n",
      "real    3360\n"
     ]
    }
   ],
   "source": [
    "group_data = df_train.groupby('label').count()\n",
    "print(group_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove non alphanumeric characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def  clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?|[0-9]\", \"\", elem))  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the cdc currently reports  deaths in general t...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>states reported  deaths a small rise from last...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politically correct woman almost uses pandemic...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indiafightscorona we have  covid testing labor...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>a tiger tested positive for covid please stay ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>autopsies prove that covid is a blood clot not...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>a post claims a covid vaccine has already been...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>aamir khan donate  cr in pm relief cares fund</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>it has been  days since the last case of covid...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6420 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "0     the cdc currently reports  deaths in general t...  real\n",
       "1     states reported  deaths a small rise from last...  real\n",
       "2     politically correct woman almost uses pandemic...  fake\n",
       "3     indiafightscorona we have  covid testing labor...  real\n",
       "4     populous states can generate large case counts...  real\n",
       "...                                                 ...   ...\n",
       "6415  a tiger tested positive for covid please stay ...  fake\n",
       "6416  autopsies prove that covid is a blood clot not...  fake\n",
       "6417  a post claims a covid vaccine has already been...  fake\n",
       "6418      aamir khan donate  cr in pm relief cares fund  fake\n",
       "6419  it has been  days since the last case of covid...  real\n",
       "\n",
       "[6420 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val  = clean_text(df_val, \"tweet\")\n",
    "df_train = clean_text(df_train, \"tweet\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def cleantext(text):\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdc currently reports deaths general discrepan...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>states reported deaths small rise last tuesday...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politically correct woman almost uses pandemic...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indiafightscorona covid testing laboratories i...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>populous states generate large case counts loo...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>tiger tested positive covid please stay away p...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>autopsies prove covid blood clot pneumonia oug...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>post claims covid vaccine already developed ca...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>aamir khan donate cr pm relief cares fund</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>days since last case covid acquired locally un...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6420 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "0     cdc currently reports deaths general discrepan...  real\n",
       "1     states reported deaths small rise last tuesday...  real\n",
       "2     politically correct woman almost uses pandemic...  fake\n",
       "3     indiafightscorona covid testing laboratories i...  real\n",
       "4     populous states generate large case counts loo...  real\n",
       "...                                                 ...   ...\n",
       "6415  tiger tested positive covid please stay away p...  fake\n",
       "6416  autopsies prove covid blood clot pneumonia oug...  fake\n",
       "6417  post claims covid vaccine already developed ca...  fake\n",
       "6418          aamir khan donate cr pm relief cares fund  fake\n",
       "6419  days since last case covid acquired locally un...  real\n",
       "\n",
       "[6420 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tweet'] = df_train['tweet'].map(lambda x: cleantext(x))\n",
    "df_val['tweet'] = df_val['tweet'].map(lambda x: cleantext(x))\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train data\n",
      "Number of tweets :  6420\n",
      "Longest tweet's length : 6412\n",
      "Average length of the tweets : 113.39579439252337\n"
     ]
    }
   ],
   "source": [
    "print('For train data')\n",
    "print(\"Number of tweets : \", len(df_train))\n",
    "print(\"Longest tweet\\'s length : \" + str(df_train.tweet.map(len).max()))\n",
    "print(\"Average length of the tweets : \" + str(df_train.tweet.map(len).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For validation data\n",
      "Number of tweets :  2140\n",
      "Longest tweet's length : 1293\n",
      "Average length of the tweets : 111.81635514018691\n"
     ]
    }
   ],
   "source": [
    "print('For validation data')\n",
    "print(\"Number of tweets : \", len(df_val))\n",
    "print(\"Longest tweet\\'s length : \" + str(df_val.tweet.map(len).max()))\n",
    "print(\"Average length of the tweets : \" + str(df_val.tweet.map(len).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit the tweet max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_text_length(text, length):\n",
    "    text = text[:length]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts that exceed 300 characters\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cdc currently reports deaths general discrepan...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>states reported deaths small rise last tuesday...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politically correct woman almost uses pandemic...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indiafightscorona covid testing laboratories i...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>populous states generate large case counts loo...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>tiger tested positive covid please stay away p...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>autopsies prove covid blood clot pneumonia oug...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>post claims covid vaccine already developed ca...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>aamir khan donate cr pm relief cares fund</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>days since last case covid acquired locally un...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "0     cdc currently reports deaths general discrepan...  real\n",
       "1     states reported deaths small rise last tuesday...  real\n",
       "2     politically correct woman almost uses pandemic...  fake\n",
       "3     indiafightscorona covid testing laboratories i...  real\n",
       "4     populous states generate large case counts loo...  real\n",
       "...                                                 ...   ...\n",
       "6415  tiger tested positive covid please stay away p...  fake\n",
       "6416  autopsies prove covid blood clot pneumonia oug...  fake\n",
       "6417  post claims covid vaccine already developed ca...  fake\n",
       "6418          aamir khan donate cr pm relief cares fund  fake\n",
       "6419  days since last case covid acquired locally un...  real\n",
       "\n",
       "[6407 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 6420\n",
    "MAX_LENGTH = 300\n",
    "print('Number of posts that exceed 300 characters')\n",
    "print(L - len(df_train[~(df_train.tweet.apply(lambda x : len(x)) > MAX_LENGTH)]))\n",
    "\n",
    "df_train = df_train[~(df_train.tweet.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "df_val.to_csv(\"validation.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdc currently reports deaths general discrepancies death counts different sources small explicable death toll stands roughly people today\n",
      "real\n"
     ]
    }
   ],
   "source": [
    "T = pd.read_csv('train.tsv', sep='\\t')\n",
    "T1, T2 = T.iloc[0, :].values\n",
    "print(T1)\n",
    "print(T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_PATH = 'cc.en.300.bin'\n",
    "if not Path(bin_PATH).is_file():\n",
    "    gdd.download_file_from_google_drive(\n",
    "        file_id='1iyOdoE3cYbhTRF-J6psKCH9W8gagd1sm',\n",
    "        dest_path='./'+bin_PATH,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x1e7f7f60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "fasttext.util.reduce_model(ft, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.word_tokenize\n",
    "w2v = ft.get_word_vector\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    # read the tsv we make and initialize some parameters\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"validation\", \"test\"]\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.label_map = {'real': 0, 'fake': 1}\n",
    "        self.tokenizer = tokenizer  # use nltk tokenizer\n",
    "    \n",
    "    # define a function that reutrn a training or testing data\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\" or self.mode == \"validation\":\n",
    "            text = self.df.iloc[idx, 0]\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            text, label = self.df.iloc[idx, :].values\n",
    "            # convert text label into index, which is more convenient to convert into tensor\n",
    "            label_id = self.label_map[label]\n",
    "            label_tensor = torch.tensor(label_id)\n",
    "            \n",
    "        # tokenize\n",
    "        word_pieces = []\n",
    "        tokens_text = self.tokenizer(text)\n",
    "        len_text = len(word_pieces)\n",
    "        \n",
    "        # convert hole token sequence into word vector\n",
    "        ids = map(w2v, tokens_text)\n",
    "        ids_list = list(ids)\n",
    "        tokens_tensor = torch.tensor(ids_list)\n",
    "\n",
    "        \n",
    "        return (tokens_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "trainset = FakeNewsDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input samples of this function is a list,\n",
    "# every element in it is a sample return by the 'FakeNewsDataset'\n",
    "\n",
    "# Every sample contains 2 tensors : \n",
    "# - tokens_tensor\n",
    "# - label_tensor\n",
    "\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    \n",
    "    # with labels or not\n",
    "    if samples[0][1] is not None:\n",
    "        label_ids = torch.stack([s[1] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # zero pading\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "    \n",
    "    return tokens_tensors, label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataLoader\n",
    "# use `collate_fn` to combine list of samples into a mini-batch\n",
    "BATCH_SIZE = 234\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens_tensors.shape   = torch.Size([234, 36, 100]) \n",
      "tensor([[[-4.2262e-01, -5.8568e-01,  1.2505e-01,  ...,  2.6792e-01,\n",
      "          -8.4427e-02, -4.7673e-02],\n",
      "         [ 1.6658e-02, -1.2981e-02,  5.4732e-02,  ...,  6.2373e-03,\n",
      "           1.7682e-02,  2.9276e-02],\n",
      "         [ 5.9510e-02, -3.1535e-02,  1.3201e-02,  ...,  6.3179e-02,\n",
      "           1.0543e-02, -6.6070e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.5433e-02, -6.4166e-02, -7.8663e-03,  ..., -8.4811e-03,\n",
      "           2.1073e-02,  8.2014e-02],\n",
      "         [ 3.1490e-02, -7.2415e-03, -3.5448e-03,  ...,  1.2513e-02,\n",
      "           1.1206e-02, -2.7145e-02],\n",
      "         [ 9.8651e-03, -8.7715e-02, -1.0489e-01,  ...,  5.2346e-02,\n",
      "          -6.6690e-03,  8.0960e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.1583e-02, -5.7975e-02, -9.2759e-02,  ...,  2.4901e-02,\n",
      "          -1.8528e-02, -3.0820e-02],\n",
      "         [ 6.2466e-02, -1.0011e-01,  2.9239e-02,  ..., -2.9377e-03,\n",
      "          -2.1086e-02,  7.1809e-03],\n",
      "         [ 3.2190e-02, -2.4433e-02, -2.5808e-01,  ..., -3.1288e-02,\n",
      "          -5.0631e-03, -1.8906e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.5135e-02, -1.2087e-02,  4.9598e-03,  ..., -3.8879e-03,\n",
      "           2.2395e-03, -7.0350e-03],\n",
      "         [-2.8112e-02, -1.9668e-01,  1.0413e-01,  ...,  7.8727e-02,\n",
      "           1.8246e-01, -3.7953e-02],\n",
      "         [-4.3020e-03, -1.1066e-01,  4.8249e-02,  ...,  2.4747e-02,\n",
      "          -2.4100e-02,  2.7307e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.8862e-01, -1.6230e-01, -4.5878e-02,  ...,  1.1364e-01,\n",
      "          -2.7561e-03,  2.6460e-02],\n",
      "         [ 1.7621e-02, -2.2337e-02, -6.7846e-02,  ...,  4.0949e-02,\n",
      "           2.6024e-02, -1.9360e-02],\n",
      "         [ 9.2192e-02, -1.1960e-01, -3.9600e-02,  ...,  6.0606e-03,\n",
      "          -2.2206e-02, -2.5260e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-5.3641e-02, -9.9449e-02,  5.3069e-03,  ..., -1.7235e-02,\n",
      "           5.8069e-02,  4.8120e-04],\n",
      "         [ 7.7952e-02,  5.1446e-02, -1.8296e-01,  ..., -3.1060e-02,\n",
      "          -5.1678e-02, -1.2792e-02],\n",
      "         [ 4.7878e-02, -9.4563e-02,  3.4983e-02,  ...,  2.1847e-02,\n",
      "           2.2531e-02, -5.1250e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]])\n",
      "\n",
      "------------------------\n",
      "label_ids.shape        = torch.Size([234])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, label_ids = data\n",
    "\n",
    "print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "\n",
    "------------------------\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "num_classes = 2\n",
    "EPOCHS = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 100\n",
    "hidden_size = 128\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            tokens_tensors = data[0]\n",
    "            outputs = model(tokens_tensors)\n",
    "            \n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            # calculate accuracy when training\n",
    "            if compute_acc:\n",
    "                labels = data[1]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # record current batch\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 19.463, acc: 0.525\n",
      "[epoch 2] loss: 19.445, acc: 0.527\n",
      "[epoch 3] loss: 19.306, acc: 0.561\n",
      "[epoch 4] loss: 18.807, acc: 0.700\n",
      "[epoch 5] loss: 17.086, acc: 0.741\n",
      "[epoch 6] loss: 14.123, acc: 0.825\n",
      "[epoch 7] loss: 10.425, acc: 0.846\n",
      "[epoch 8] loss: 9.295, acc: 0.872\n",
      "[epoch 9] loss: 8.214, acc: 0.888\n",
      "[epoch 10] loss: 7.671, acc: 0.886\n",
      "[epoch 11] loss: 7.175, acc: 0.872\n",
      "[epoch 12] loss: 7.031, acc: 0.894\n",
      "[epoch 13] loss: 6.361, acc: 0.922\n",
      "[epoch 14] loss: 5.933, acc: 0.927\n",
      "[epoch 15] loss: 5.480, acc: 0.936\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train model\n",
    "model.train()\n",
    "\n",
    "# using Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        tokens_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(tokens_tensors)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # record batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # calculate accuracy\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valiset = FakeNewsDataset(\"validation\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valiloader = DataLoader(valiset, batch_size=64, collate_fn=create_mini_batch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    validations = get_predictions(model, valiloader)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations_numpy = validations.cpu().clone().numpy()\n",
    "validations_numpy = validations_numpy.reshape((2140, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(1,2141)\n",
    "ids = ids.reshape((2140, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    1],\n",
       "       [   2,    1],\n",
       "       [   3,    1],\n",
       "       ...,\n",
       "       [2138,    1],\n",
       "       [2139,    0],\n",
       "       [2140,    0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validations_array = np.concatenate((ids, validations_numpy), axis=1)\n",
    "validations_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validations = pd.DataFrame(data = validations_array, columns=[\"id\", \"label\"])\n",
    "df_validations['label'] = df_validations['label'].map({0:'real', 1:'fake'})\n",
    "# df_validations.to_csv('answer.txt', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.883, acc: 0.883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "f1 = f1_score(df_val['label'], df_validations['label'], average = 'weighted')\n",
    "Acc = accuracy_score(df_val['label'], df_validations['label'])\n",
    "\n",
    "print('f1: %.3f, acc: %.3f' % (f1, Acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
